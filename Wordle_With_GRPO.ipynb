{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Worlde With GRPO** (RL + Constraint-Aware Inference)"
      ],
      "metadata": {
        "id": "Ny3HzsSyaGJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This project explores **reinforcement learning** for symbolic reasoning by training a language model to play Wordle using **GRPO** (Group Relative Policy Optimization).\n",
        "\n",
        "**Key idea**\n",
        "* The model learns guess preferences via RL.\n",
        "* Exact Wordle logic is enforced at inference time using a constraint-aware reranker.\n",
        "* The secret word is never shown to the model."
      ],
      "metadata": {
        "id": "G-a8gF4QVNQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install libraries**"
      ],
      "metadata": {
        "id": "vfFDEoxZVMq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  -U -q trl peft math_verify\n",
        "!pip install -q transformers datasets accelerate\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "NRM6lKlhqruB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "m-k9BErObiB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from trl import GRPOConfig\n",
        "from trl import GRPOTrainer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch, re\n",
        "from collections import Counter, defaultdict"
      ],
      "metadata": {
        "id": "Iu55i6NAJJO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Login to HuggingFace hub**"
      ],
      "metadata": {
        "id": "hPfirOt0bscd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "3oFYGFs4q3rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the dataset**"
      ],
      "metadata": {
        "id": "AWoI-VT-e-Q9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8-j-UEBmBiQ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preview the dataset**"
      ],
      "metadata": {
        "id": "MrTKCx0dfFQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9_KKsqaBmDJ-",
        "outputId": "e6b70be2-118c-441b-915a-8551720778bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              prompt  \\\n",
              "0  <|im_start|>system\\n\\nYou are playing Wordle, ...   \n",
              "1  <|im_start|>system\\n\\nYou are playing Wordle, ...   \n",
              "2  <|im_start|>system\\n\\nYou are playing Wordle, ...   \n",
              "3  <|im_start|>system\\n\\nYou are playing Wordle, ...   \n",
              "4  <|im_start|>system\\n\\nYou are playing Wordle, ...   \n",
              "\n",
              "                                           word_list  \\\n",
              "0  https://raw.githubusercontent.com/arnavgarg1/a...   \n",
              "1  https://raw.githubusercontent.com/arnavgarg1/a...   \n",
              "2  https://raw.githubusercontent.com/arnavgarg1/a...   \n",
              "3  https://raw.githubusercontent.com/arnavgarg1/a...   \n",
              "4  https://raw.githubusercontent.com/arnavgarg1/a...   \n",
              "\n",
              "                                  past_guess_history secret  \n",
              "0                                                 []  ABHOR  \n",
              "1  [['CRANE', 'C(x) R(x) A(-) N(x) E(-)'], ['SWEA...  ALLEY  \n",
              "2  [['CRANE', 'C(x) R(x) A(-) N(x) E(x)'], ['ADUL...  ALLOT  \n",
              "3            [['CRANE', 'C(x) R(x) A(-) N(-) E(x)']]  ANNUL  \n",
              "4  [['CRANE', 'C(x) R(x) A(-) N(x) E(x)'], ['BLOA...  BATTY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26266c45-1aff-4baf-a384-c0bdc74bce8c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>word_list</th>\n",
              "      <th>past_guess_history</th>\n",
              "      <th>secret</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|im_start|&gt;system\\n\\nYou are playing Wordle, ...</td>\n",
              "      <td>https://raw.githubusercontent.com/arnavgarg1/a...</td>\n",
              "      <td>[]</td>\n",
              "      <td>ABHOR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|im_start|&gt;system\\n\\nYou are playing Wordle, ...</td>\n",
              "      <td>https://raw.githubusercontent.com/arnavgarg1/a...</td>\n",
              "      <td>[['CRANE', 'C(x) R(x) A(-) N(x) E(-)'], ['SWEA...</td>\n",
              "      <td>ALLEY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|im_start|&gt;system\\n\\nYou are playing Wordle, ...</td>\n",
              "      <td>https://raw.githubusercontent.com/arnavgarg1/a...</td>\n",
              "      <td>[['CRANE', 'C(x) R(x) A(-) N(x) E(x)'], ['ADUL...</td>\n",
              "      <td>ALLOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|im_start|&gt;system\\n\\nYou are playing Wordle, ...</td>\n",
              "      <td>https://raw.githubusercontent.com/arnavgarg1/a...</td>\n",
              "      <td>[['CRANE', 'C(x) R(x) A(-) N(-) E(x)']]</td>\n",
              "      <td>ANNUL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|im_start|&gt;system\\n\\nYou are playing Wordle, ...</td>\n",
              "      <td>https://raw.githubusercontent.com/arnavgarg1/a...</td>\n",
              "      <td>[['CRANE', 'C(x) R(x) A(-) N(x) E(x)'], ['BLOA...</td>\n",
              "      <td>BATTY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26266c45-1aff-4baf-a384-c0bdc74bce8c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-26266c45-1aff-4baf-a384-c0bdc74bce8c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-26266c45-1aff-4baf-a384-c0bdc74bce8c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-69e34baf-9d43-4a65-940d-a6278073baa7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69e34baf-9d43-4a65-940d-a6278073baa7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-69e34baf-9d43-4a65-940d-a6278073baa7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 76,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 76,\n        \"samples\": [\n          \"<|im_start|>system\\n\\nYou are playing Wordle, a word-guessing game.\\n\\n### Game Rules:\\n- You have **6 tries** to guess a secret **5-letter** word.\\n- Each guess must be a valid **5-letter English word**.\\n- After each guess, you will receive feedback indicating how close your guess was.\\n\\n### Feedback Format:\\nEach letter in your guess will receive one of three symbols:\\n1. \\u2713 : The letter is in the word and in the CORRECT position.\\n2. - : The letter is in the word but in the WRONG position.\\n3. x : The letter is NOT in the word.\\n\\n### Example:\\nSecret Word: BRISK\\n\\nGuess 1: STORM \\u2192 Feedback: S(-) T(x) O(x) R(-) M(x)\\nGuess 2: BRAVE \\u2192 Feedback: B(\\u2713) R(\\u2713) A(x) V(x) E(x)\\nGuess 3: BRISK \\u2192 Feedback: B(\\u2713) R(\\u2713) I(\\u2713) S(\\u2713) K(\\u2713)\\n\\n### Response Format:\\nThink through the problem and feedback step by step. Make sure to first add your step by step thought process within <think> </think> tags. Then, return your guessed word in the following format: <guess> guessed-word </guess>.\\n<|im_end|>\\n<|im_start|>user\\nMake a new 5-letter word guess.\\n\\n Here is some previous feedback:\\nGuess 1: CRANE -> Feedback: C(x) R(x) A(-) N(x) E(x)\\nGuess 2: BLOAT -> Feedback: B(\\u2713) L(x) O(x) A(-) T(-)<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>\",\n          \"<|im_start|>system\\n\\nYou are playing Wordle, a word-guessing game.\\n\\n### Game Rules:\\n- You have **6 tries** to guess a secret **5-letter** word.\\n- Each guess must be a valid **5-letter English word**.\\n- After each guess, you will receive feedback indicating how close your guess was.\\n\\n### Feedback Format:\\nEach letter in your guess will receive one of three symbols:\\n1. \\u2713 : The letter is in the word and in the CORRECT position.\\n2. - : The letter is in the word but in the WRONG position.\\n3. x : The letter is NOT in the word.\\n\\n### Example:\\nSecret Word: BRISK\\n\\nGuess 1: STORM \\u2192 Feedback: S(-) T(x) O(x) R(-) M(x)\\nGuess 2: BRAVE \\u2192 Feedback: B(\\u2713) R(\\u2713) A(x) V(x) E(x)\\nGuess 3: BRISK \\u2192 Feedback: B(\\u2713) R(\\u2713) I(\\u2713) S(\\u2713) K(\\u2713)\\n\\n### Response Format:\\nThink through the problem and feedback step by step. Make sure to first add your step by step thought process within <think> </think> tags. Then, return your guessed word in the following format: <guess> guessed-word </guess>.\\n<|im_end|>\\n<|im_start|>user\\nMake a new 5-letter word guess.\\n\\n Here is some previous feedback:\\nGuess 1: CRANE -> Feedback: C(-) R(-) A(x) N(x) E(-)\\nGuess 2: RELIC -> Feedback: R(-) E(\\u2713) L(x) I(x) C(-)<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>\",\n          \"<|im_start|>system\\n\\nYou are playing Wordle, a word-guessing game.\\n\\n### Game Rules:\\n- You have **6 tries** to guess a secret **5-letter** word.\\n- Each guess must be a valid **5-letter English word**.\\n- After each guess, you will receive feedback indicating how close your guess was.\\n\\n### Feedback Format:\\nEach letter in your guess will receive one of three symbols:\\n1. \\u2713 : The letter is in the word and in the CORRECT position.\\n2. - : The letter is in the word but in the WRONG position.\\n3. x : The letter is NOT in the word.\\n\\n### Example:\\nSecret Word: BRISK\\n\\nGuess 1: STORM \\u2192 Feedback: S(-) T(x) O(x) R(-) M(x)\\nGuess 2: BRAVE \\u2192 Feedback: B(\\u2713) R(\\u2713) A(x) V(x) E(x)\\nGuess 3: BRISK \\u2192 Feedback: B(\\u2713) R(\\u2713) I(\\u2713) S(\\u2713) K(\\u2713)\\n\\n### Response Format:\\nThink through the problem and feedback step by step. Make sure to first add your step by step thought process within <think> </think> tags. Then, return your guessed word in the following format: <guess> guessed-word </guess>.\\n<|im_end|>\\n<|im_start|>user\\nMake a new 5-letter word guess.\\n\\n Here is some previous feedback:\\nGuess 1: CRANE -> Feedback: C(\\u2713) R(-) A(x) N(x) E(x)\\nGuess 2: CURLY -> Feedback: C(\\u2713) U(x) R(-) L(x) Y(x)<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_list\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://raw.githubusercontent.com/arnavgarg1/arnavgarg1/refs/heads/main/five_letter_words.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"past_guess_history\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"[['CRANE', 'C(x) R(x) A(-) N(x) E(x)'], ['BLOAT', 'B(\\u2713) L(x) O(x) A(-) T(-)']]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"secret\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 76,\n        \"samples\": [\n          \"BATTY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw0WnISimDZS",
        "outputId": "34448670-7fd4-4089-e7ed-49b79c76deea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 76 entries, 0 to 75\n",
            "Data columns (total 4 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   prompt              76 non-null     object\n",
            " 1   word_list           76 non-null     object\n",
            " 2   past_guess_history  76 non-null     object\n",
            " 3   secret              76 non-null     object\n",
            "dtypes: object(4)\n",
            "memory usage: 2.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parse and process the necessary columns for convenience**"
      ],
      "metadata": {
        "id": "haJjY4SXgcZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_history(x):\n",
        "    if x == \"[]\":\n",
        "        return []\n",
        "    return ast.literal_eval(x)\n",
        "\n",
        "df['history'] = df['past_guess_history'].apply(parse_history)"
      ],
      "metadata": {
        "id": "ZK5FbUSkmDfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['history'].iloc[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKnLwTjCmDi3",
        "outputId": "fed75c97-1386-4c2d-c1fe-6ab402212dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['CRANE', 'C(x) R(x) A(-) N(-) E(x)']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_state(prompt, history):\n",
        "    lines = [prompt.strip(), \"\\nCurrent guesses:\"]\n",
        "    if len(history) == 0:\n",
        "        lines.append(\"None\")\n",
        "    else:\n",
        "        for i, (guess, fb) in enumerate(history):\n",
        "            lines.append(f\"Guess {i+1}: {guess} -> {fb}\")\n",
        "    lines.append(\"\\nNext guess:\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "df['state_text'] = df.apply(\n",
        "    lambda r: build_state(r['prompt'], r['history']),\n",
        "    axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "tTLoT0RDmDmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['state_text'].iloc[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLBuV0MdmDpi",
        "outputId": "704c3df0-b3e5-4c9c-faf5-4bb878dcea98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "\n",
            "You are playing Wordle, a word-guessing game.\n",
            "\n",
            "### Game Rules:\n",
            "- You have **6 tries** to guess a secret **5-letter** word.\n",
            "- Each guess must be a valid **5-letter English word**.\n",
            "- After each guess, you will receive feedback indicating how close your guess was.\n",
            "\n",
            "### Feedback Format:\n",
            "Each letter in your guess will receive one of three symbols:\n",
            "1. ✓ : The letter is in the word and in the CORRECT position.\n",
            "2. - : The letter is in the word but in the WRONG position.\n",
            "3. x : The letter is NOT in the word.\n",
            "\n",
            "### Example:\n",
            "Secret Word: BRISK\n",
            "\n",
            "Guess 1: STORM → Feedback: S(-) T(x) O(x) R(-) M(x)\n",
            "Guess 2: BRAVE → Feedback: B(✓) R(✓) A(x) V(x) E(x)\n",
            "Guess 3: BRISK → Feedback: B(✓) R(✓) I(✓) S(✓) K(✓)\n",
            "\n",
            "### Response Format:\n",
            "Think through the problem and feedback step by step. Make sure to first add your step by step thought process within <think> </think> tags. Then, return your guessed word in the following format: <guess> guessed-word </guess>.\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "Make a new 5-letter word guess.\n",
            "\n",
            " Here is some previous feedback:\n",
            "Guess 1: CRANE -> Feedback: C(x) R(x) A(-) N(x) E(-)\n",
            "Guess 2: SWEAT -> Feedback: S(x) W(x) E(-) A(-) T(x)<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Let me solve this step by step.\n",
            "<think>\n",
            "\n",
            "Current guesses:\n",
            "Guess 1: CRANE -> C(x) R(x) A(-) N(x) E(-)\n",
            "Guess 2: SWEAT -> S(x) W(x) E(-) A(-) T(x)\n",
            "\n",
            "Next guess:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove the rows with no past guesses**"
      ],
      "metadata": {
        "id": "m2MNFwG_gt5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_action(history):\n",
        "    if len(history) == 0:\n",
        "        return None\n",
        "    return history[-1][0]\n",
        "\n",
        "df['action'] = df['history'].apply(extract_action)"
      ],
      "metadata": {
        "id": "X7_1z8FqFLkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['action'].notna()].reset_index(drop=True)\n",
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq-9aQ2SFLrl",
        "outputId": "0dafe7d5-d340-47b9-81cd-0aa755a65be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trl_ds = Dataset.from_pandas(\n",
        "    df[['state_text', 'secret']]\n",
        ").rename_columns({\n",
        "    \"state_text\": \"prompt\",\n",
        "    \"secret\": \"solution\"\n",
        "})"
      ],
      "metadata": {
        "id": "HGaPJMgdPRO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the reward function**"
      ],
      "metadata": {
        "id": "qhv5HGHxjRVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wordle_reward(prompts, completions, solution, **kwargs):\n",
        "    \"\"\"\n",
        "    prompts: List[str]\n",
        "    completions: List[str]\n",
        "    solution: List[str]  (same length as completions)\n",
        "    \"\"\"\n",
        "\n",
        "    rewards = []\n",
        "\n",
        "    for guess, secret in zip(completions, solution):\n",
        "        guess = guess.strip().upper()\n",
        "        secret = secret.upper()\n",
        "\n",
        "        # invalid guess\n",
        "        if len(guess) != 5:\n",
        "            rewards.append(-0.5)\n",
        "            continue\n",
        "\n",
        "        r = 0.0\n",
        "        for g, s in zip(guess, secret):\n",
        "            if g == s:\n",
        "                r += 0.2\n",
        "            elif g in secret:\n",
        "                r += 0.05\n",
        "\n",
        "        if guess == secret:\n",
        "            r += 1.0\n",
        "\n",
        "        rewards.append(r)\n",
        "\n",
        "    return rewards"
      ],
      "metadata": {
        "id": "DdqJWbWwPRSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the GRPO training arguments**"
      ],
      "metadata": {
        "id": "CenbIu5ilzw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = GRPOConfig(\n",
        "    output_dir=\"Qwen2.5-0.5B-Wordle-GRPO\",\n",
        "    learning_rate=1e-5,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=3,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "\n",
        "    max_prompt_length=256,\n",
        "    max_completion_length=8,  # 5-letter word + buffer\n",
        "    num_generations=4,\n",
        "\n",
        "    logging_steps=5,\n",
        "    report_to=\"tensorboard\",\n",
        "    save_strategy=\"no\"\n",
        ")"
      ],
      "metadata": {
        "id": "_MJZ4_P9PRVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the model and GRPO trainer**"
      ],
      "metadata": {
        "id": "cK83u86gmqKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=trl_ds,\n",
        "    reward_funcs=wordle_reward\n",
        ")"
      ],
      "metadata": {
        "id": "ghrpwAyhPRX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "5lnRt2ctnMcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "9uyPhOoaMQU4",
        "outputId": "131051a3-7a00-4d4c-b040-40df1a49ab60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12/12 01:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>-0.021600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>-0.008200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=12, training_loss=-0.0033825250963370004, metrics={'train_runtime': 101.6316, 'train_samples_per_second': 2.184, 'train_steps_per_second': 0.118, 'total_flos': 0.0, 'train_loss': -0.0033825250963370004})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training completed with training_loss=-0.0033825250963370004"
      ],
      "metadata": {
        "id": "Mke6mKWToVuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the model**"
      ],
      "metadata": {
        "id": "hghCZ13SnnGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"qwen2.5-0.5b-wordle-grpo\"\n",
        "\n",
        "model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTZyvl9yMQYP",
        "outputId": "434c45f4-f130-4fb2-e417-c8598fee6c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('qwen2.5-0.5b-wordle-grpo/tokenizer_config.json',\n",
              " 'qwen2.5-0.5b-wordle-grpo/special_tokens_map.json',\n",
              " 'qwen2.5-0.5b-wordle-grpo/chat_template.jinja',\n",
              " 'qwen2.5-0.5b-wordle-grpo/vocab.json',\n",
              " 'qwen2.5-0.5b-wordle-grpo/merges.txt',\n",
              " 'qwen2.5-0.5b-wordle-grpo/added_tokens.json',\n",
              " 'qwen2.5-0.5b-wordle-grpo/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Push the model to HuggingFace**"
      ],
      "metadata": {
        "id": "39gQ2wEdnytN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"username/qwen2.5-0.5b-wordle-grpo\")\n",
        "tokenizer.push_to_hub(\"username/qwen2.5-0.5b-wordle-grpo\")"
      ],
      "metadata": {
        "id": "DilytAj1lj1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the model**"
      ],
      "metadata": {
        "id": "dJnzyNrDoerX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"username/qwen2.5-0.5b-wordle-grpo\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(repo_id, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    repo_id,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ").eval()"
      ],
      "metadata": {
        "id": "PGKTk-s5lj4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test the model with simple prompt**"
      ],
      "metadata": {
        "id": "-TKSByRNpYAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompt = \"\"\"You are playing Wordle.\n",
        "Rules:\n",
        "- Guess a 5-letter word.\n",
        "- Respond with ONLY the word.\n",
        "\n",
        "Previous guesses:\n",
        "CRANE → C(x) R(x) A(-) N(x) E(-)\n",
        "\n",
        "Your guess:\n",
        "\"\"\"\n",
        "\n",
        "test_secret = \"ALLEY\"   # ← NOT passed to model"
      ],
      "metadata": {
        "id": "oQKrqKYcqE7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def single_test(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=8,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,# deterministic\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "    text = tokenizer.decode(\n",
        "        output[0][inputs[\"input_ids\"].shape[-1]:],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    match = re.search(r\"[A-Za-z]{5}\", text)\n",
        "    return match.group(0).upper() if match else \"XXXXX\""
      ],
      "metadata": {
        "id": "NIFpfa2Rlj8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guess = single_test(test_prompt)\n",
        "print(\"Model guess:\", guess)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkHd86OVp0UK",
        "outputId": "545b5c74-c449-4803-9bab-209e1c5d73e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model guess: CURRE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RL model is able to guess a five letter word"
      ],
      "metadata": {
        "id": "jyWX6pa1qmZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Building Gameplay Loop with constraint-aware reranker**"
      ],
      "metadata": {
        "id": "DtW-1vRttdL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the base prompt**"
      ],
      "metadata": {
        "id": "5r8kY9aluGjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PROMPT = \"\"\"You are playing Wordle.\n",
        "Rules:\n",
        "- Guess a 5-letter word.\n",
        "- Respond with ONLY the word.\n",
        "\n",
        "Previous guesses:\n",
        "\"\"\"\n",
        "\n",
        "def build_prompt(history):\n",
        "    prompt = BASE_PROMPT\n",
        "    if not history:\n",
        "        prompt += \"(none)\\n\"\n",
        "    else:\n",
        "        for guess, fb in history:\n",
        "            prompt += f\"{guess} → {fb}\\n\"\n",
        "    prompt += \"\\nYour guess:\\n\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "7Po6lESBr4-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define generate guess function**"
      ],
      "metadata": {
        "id": "lLSdsnVPuKut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_guess(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=8,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "    text = tokenizer.decode(\n",
        "        output[0][inputs[\"input_ids\"].shape[-1]:],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    match = re.search(r\"[A-Za-z]{5}\", text)\n",
        "    return match.group(0).upper() if match else \"XXXXX\""
      ],
      "metadata": {
        "id": "bnct4KpVserO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define wordle feedback based on the guesses**"
      ],
      "metadata": {
        "id": "rmhLBuE7uOn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wordle_feedback(guess, secret):\n",
        "    feedback = []\n",
        "    secret_chars = list(secret)\n",
        "\n",
        "    # First pass: correct positions\n",
        "    for i, g in enumerate(guess):\n",
        "        if g == secret[i]:\n",
        "            feedback.append(\"✓\")\n",
        "            secret_chars[i] = None\n",
        "        else:\n",
        "            feedback.append(None)\n",
        "\n",
        "    # Second pass: wrong positions\n",
        "    for i, g in enumerate(guess):\n",
        "        if feedback[i] is None:\n",
        "            if g in secret_chars:\n",
        "                feedback[i] = \"-\"\n",
        "                secret_chars[secret_chars.index(g)] = None\n",
        "            else:\n",
        "                feedback[i] = \"x\"\n",
        "\n",
        "    return \" \".join(f\"{g}({f})\" for g, f in zip(guess, feedback))"
      ],
      "metadata": {
        "id": "uSBYCAO5p0XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a function to parse feedback**"
      ],
      "metadata": {
        "id": "hWlFOOvZudp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_feedback(feedback_str):\n",
        "    # \"C(x) R(✓) A(-) N(x) E(x)\"\n",
        "    feedback = []\n",
        "    for token in feedback_str.split():\n",
        "        letter = token[0]\n",
        "        status = token[2]  # x, -, or ✓\n",
        "        feedback.append((letter, status))\n",
        "    return feedback"
      ],
      "metadata": {
        "id": "ILtizMqTxqsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a function to with constraints based on the game**"
      ],
      "metadata": {
        "id": "tCt7ycVpujsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def satisfies_constraints(guess, history):\n",
        "    guess = guess.upper()\n",
        "    guess_counts = Counter(guess)\n",
        "\n",
        "    # Never repeat guesses\n",
        "    if guess in {g for g, _ in history}:\n",
        "        return False\n",
        "\n",
        "    min_counts = defaultdict(int)\n",
        "    max_counts = defaultdict(lambda: 5)\n",
        "    forbidden_positions = defaultdict(set)\n",
        "    required_positions = {}\n",
        "\n",
        "    for prev_guess, fb_str in history:\n",
        "        prev_guess = prev_guess.upper()\n",
        "        feedback = parse_feedback(fb_str)\n",
        "\n",
        "        for i, (letter, status) in enumerate(feedback):\n",
        "            if status == \"✓\":\n",
        "                required_positions[i] = letter\n",
        "                min_counts[letter] += 1\n",
        "\n",
        "            elif status == \"-\":\n",
        "                forbidden_positions[letter].add(i)\n",
        "                min_counts[letter] += 1\n",
        "\n",
        "            elif status == \"x\":\n",
        "                if letter not in min_counts:\n",
        "                    max_counts[letter] = 0\n",
        "\n",
        "    # Enforce required positions (THIS WAS MISSING)\n",
        "    for pos, letter in required_positions.items():\n",
        "        if guess[pos] != letter:\n",
        "            return False\n",
        "\n",
        "    # Enforce forbidden positions\n",
        "    for letter, positions in forbidden_positions.items():\n",
        "        for pos in positions:\n",
        "            if guess[pos] == letter:\n",
        "                return False\n",
        "\n",
        "    # Enforce counts\n",
        "    for l, c in min_counts.items():\n",
        "        if guess_counts[l] < c:\n",
        "            return False\n",
        "    for l, c in max_counts.items():\n",
        "        if guess_counts[l] > c:\n",
        "            return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "RYnhOZ8tF06a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a function for constraint scoring**"
      ],
      "metadata": {
        "id": "WDkuzuzAuwYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def constraint_score(guess, history):\n",
        "    score = 0\n",
        "    guess = guess.upper()\n",
        "\n",
        "    for prev_guess, fb_str in history:\n",
        "        feedback = parse_feedback(fb_str)\n",
        "\n",
        "        for i, (letter, status) in enumerate(feedback):\n",
        "            if status == \"✓\" and guess[i] == letter:\n",
        "                score += 2\n",
        "            elif status == \"-\" and letter in guess and guess[i] != letter:\n",
        "                score += 1\n",
        "            elif status == \"x\" and letter not in guess:\n",
        "                score += 0.5\n",
        "            else:\n",
        "                score -= 1\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "VPZgna2_GLZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to generate reranked guess**"
      ],
      "metadata": {
        "id": "BqbGp0UYu318"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_reranked_guess(prompt, history, num_samples=64):\n",
        "    candidates = [generate_guess(prompt) for _ in range(num_samples)]\n",
        "\n",
        "    valid = [\n",
        "        g for g in candidates\n",
        "        if len(g) == 5 and satisfies_constraints(g, history)\n",
        "    ]\n",
        "\n",
        "    if not valid:\n",
        "        return max(candidates, key=lambda g: constraint_score(g, history))\n",
        "\n",
        "    # Prefer guesses that satisfy MORE confirmed positions\n",
        "    def score(g):\n",
        "        s = 0\n",
        "        for prev, fb in history:\n",
        "            for i, (l, st) in enumerate(parse_feedback(fb)):\n",
        "                if st == \"✓\" and g[i] == l:\n",
        "                    s += 2\n",
        "        return s\n",
        "\n",
        "    return max(valid, key=score)"
      ],
      "metadata": {
        "id": "zJbsjV06F1Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Putting everything together**"
      ],
      "metadata": {
        "id": "DTdNRFZEvC-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def play_wordle(secret, model, tokenizer):\n",
        "    history = []\n",
        "\n",
        "    for step in range(6):\n",
        "        prompt = build_prompt(history)\n",
        "        guess = generate_reranked_guess(prompt, history)\n",
        "\n",
        "        feedback = wordle_feedback(guess, secret)\n",
        "        history.append((guess, feedback))\n",
        "\n",
        "        print(f\"Step {step+1}: {guess} → {feedback}\")\n",
        "\n",
        "        if guess == secret:\n",
        "            print(\"✅ Solved!\")\n",
        "            return True, step + 1\n",
        "\n",
        "    print(\"❌ Failed. Secret was:\", secret)\n",
        "    return False, 6"
      ],
      "metadata": {
        "id": "aW1SSSaxF1Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set the model in evaluation mode**"
      ],
      "metadata": {
        "id": "RuI7GWDSF7Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbSJINA0F1G0",
        "outputId": "bdedd107-dbb5-4930-8c25-cd9676d6ddcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896, padding_idx=151643)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sanity test**"
      ],
      "metadata": {
        "id": "hjrbpnKavIpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure generation is not deterministic\n",
        "print(generate_guess(build_prompt([])))\n",
        "print(generate_guess(build_prompt([])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IjFChhHF1JS",
        "outputId": "ab28a860-65d0-488d-f484-6970e48dcad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOODL\n",
            "OPPON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single test to check if the model is behaving as expected**"
      ],
      "metadata": {
        "id": "ELngewIEvOoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = [\n",
        "    (\"CRANE\", \"C(x) R(x) A(-) N(x) E(-)\")\n",
        "]\n",
        "\n",
        "prompt = build_prompt(history)\n",
        "guess = generate_reranked_guess(prompt, history)\n",
        "\n",
        "print(\"Prompt:\\n\", prompt)\n",
        "print(\"Model guess:\", guess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8DOzBKvGpMb",
        "outputId": "cc97f0e0-3437-4c12-9e08-90e38f284061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            " You are playing Wordle.\n",
            "Rules:\n",
            "- Guess a 5-letter word.\n",
            "- Respond with ONLY the word.\n",
            "\n",
            "Previous guesses:\n",
            "CRANE → C(x) R(x) A(-) N(x) E(-)\n",
            "\n",
            "Your guess:\n",
            "\n",
            "Model guess: SATEW\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model was able to make a new guess without the letters that are not there in the secret word and also place the required letters in the different positions based on the previous guesses."
      ],
      "metadata": {
        "id": "gsAvakh7vUMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Playing the wordle game**"
      ],
      "metadata": {
        "id": "0ZUrVHaYwTAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "play_wordle(\"BRICK\", model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY8d15T4GpPq",
        "outputId": "c38e77a7-2b98-4ef7-e8a2-a32e6a54b97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: DUBLI → D(x) U(x) B(-) L(x) I(-)\n",
            "Step 2: FIRST → F(x) I(-) R(-) S(x) T(x)\n",
            "Step 3: BROOK → B(✓) R(✓) O(x) O(x) K(✓)\n",
            "Step 4: BRACK → B(✓) R(✓) A(x) C(✓) K(✓)\n",
            "Step 5: BRACK → B(✓) R(✓) A(x) C(✓) K(✓)\n",
            "Step 6: BRACK → B(✓) R(✓) A(x) C(✓) K(✓)\n",
            "❌ Failed. Secret was: BRICK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the above output, RL model with GRPO guessed the words and came close to guessing the secret word. Considering the model was trained on small dataset and qwen2.5-0.5b, there is room for improvement. But overall it is working as expected.  "
      ],
      "metadata": {
        "id": "D9WynD_Two9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Takeaways**"
      ],
      "metadata": {
        "id": "Uoa8yjXExSor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Reinforcement learning teaches preferences.\n",
        "* Symbolic constraints guarantee correctness.\n",
        "\n",
        "This project demonstrates how to combine both cleanly for structured reasoning tasks."
      ],
      "metadata": {
        "id": "Ekol26U3xWjV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLhEKnnfGpS7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}